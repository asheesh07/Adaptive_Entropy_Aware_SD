{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f49f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.speculative_engine import SpeculativeEngine\n",
    "from core.draft_model import DraftModel\n",
    "from core.target_model import TargetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04732dad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "draft = DraftModel(\"TinyLlama/TinyLlama-1.1B\", device=device)\n",
    "target = TargetModel(\"meta-llama/Llama-2-7b\", device=device)\n",
    "\n",
    "engine = SpeculativeEngine(\n",
    "    draft_model=draft,\n",
    "    target_model=target,\n",
    "    max_k=8,\n",
    "    entropy_bins=[1.2, 2.2, 3.0],\n",
    "    k_values=[8, 4, 2, 0],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc41ea9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"The theory of evolution explains\"\n",
    "input_ids = target.tokenizer(\n",
    "    prompt, return_tensors=\"pt\"\n",
    ").input_ids.to(device)\n",
    "\n",
    "# Vanilla decoding\n",
    "target.performance_tracker.reset()\n",
    "target.performance_tracker.start()\n",
    "\n",
    "outputs = target.model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "target.performance_tracker.stop()\n",
    "baseline_latency = target.performance_tracker.latency_per_token_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8aa9e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spec_output = engine.decode(input_ids, max_tokens=50)\n",
    "spec_latency = engine.performance_tracker.latency_per_token_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a85bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(\n",
    "    [\"Vanilla\", \"Speculative\"],\n",
    "    [baseline_latency, spec_latency]\n",
    ")\n",
    "plt.ylabel(\"Latency per Token (ms)\")\n",
    "plt.title(\"Latency Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ba0de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Speculative target calls:\",\n",
    "      engine.performance_tracker.target_forward_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8378211",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vanilla_text = target.tokenizer.decode(\n",
    "    outputs[0], skip_special_tokens=True\n",
    ")\n",
    "spec_text = target.tokenizer.decode(\n",
    "    spec_output[0], skip_special_tokens=True\n",
    ")\n",
    "\n",
    "assert vanilla_text == spec_text\n",
    "print(\"âœ… Output equivalence verified\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
