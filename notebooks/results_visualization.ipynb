{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b50f49f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from core.speculative_engine import SpeculativeEngine\n",
    "from core.draft_model import DraftModel\n",
    "from core.target_model import TargetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04732dad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "draft = DraftModel(tokenizer,\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", device=device)\n",
    "target = TargetModel(tokenizer,\"meta-llama/Llama-2-7b-hf\", device=device)\n",
    "\n",
    "engine = SpeculativeEngine(\n",
    "    draft_model=draft,\n",
    "    target_model=target,\n",
    "    max_k=4,\n",
    "    entropy_bins=[0.5,1.5,2.5],\n",
    "    k_values=[ 4,3, 2, 1],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc41ea9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prompt = \"The theory of evolution explains\"\n",
    "input_ids = target.tokenizer(\n",
    "    prompt, return_tensors=\"pt\"\n",
    ").input_ids.to(device)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = target.model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=50,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "tokens_generated = outputs.shape[1] - input_ids.shape[1]\n",
    "\n",
    "latency_per_token_ms = (total_time / tokens_generated) * 1000\n",
    "throughput = tokens_generated / total_time\n",
    "\n",
    "print(\"=== VANILLA BASELINE ===\")\n",
    "print(f\"Total time (s): {total_time:.4f}\")\n",
    "print(f\"Tokens generated: {tokens_generated}\")\n",
    "print(f\"Latency per token (ms): {latency_per_token_ms:.2f}\")\n",
    "print(f\"Throughput (tok/s): {throughput:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8aa9e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spec_output = engine.decode(input_ids, max_tokens=50)\n",
    "spec_latency = engine.performance_tracker.latency_per_token_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a85bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(\n",
    "    [\"Vanilla\", \"Speculative\"],\n",
    "    [latency_per_token_ms, spec_latency]\n",
    ")\n",
    "plt.ylabel(\"Latency per Token (ms)\")\n",
    "plt.title(\"Latency Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ba0de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Speculative target calls:\",\n",
    "      engine.performance_tracker.target_forward_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8378211",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Decode texts\n",
    "vanilla_text = target.tokenizer.decode(\n",
    "    outputs[0], skip_special_tokens=True\n",
    ")\n",
    "spec_text = target.tokenizer.decode(\n",
    "    spec_output[0], skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== VANILLA OUTPUT ===\")\n",
    "print(vanilla_text)\n",
    "\n",
    "print(\"\\n=== SPECULATIVE OUTPUT ===\")\n",
    "print(spec_text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
